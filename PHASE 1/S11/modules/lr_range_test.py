# -*- coding: utf-8 -*-
"""lr_range_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lhynuUZ6GKJwSFNPuxpz7nrhmRdmPPu1
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
# %matplotlib inline
import matplotlib.pyplot as plt
import torchvision
from tqdm import tqdm
import numpy as np
import torchvision.transforms as transforms
import albumentations
from albumentations.pytorch import ToTensor
import random
import copy

Lr_acc = []
Lr = []
#train_acc = []
#train_losses = []
def LR_Range_Test(max_lr, min_lr,device,epoch,model,loss_func,train_loader_Albumentation,momemtum = 0.9,weight_decay=0.05 ):  
    step = (max_lr - min_lr )/epoch
    lr = min_lr
    for i in range(epoch):
        model = copy.deepcopy(model) #copy all its nested objects.
        optimizer = optim.SGD(model.parameters(), lr=lr ,momentum=momemtum,weight_decay=weight_decay ) 
        lr += (max_lr - min_lr)/epoch
        model.train()
        pbar = tqdm(train_loader_Albumentation)
        correct = 0
        processed = 0
        #train_loss = 0
        for batch_idx, (data, target) in enumerate(pbar):
            # get the inputs
            data, target = data.to(device), target.to(device)

            # zero the parameter gradients  
            optimizer.zero_grad()

            # predict  
            y_pred =model(data)

            # loss
            loss = loss_func(y_pred, target)

            # backprop  
            loss.backward()
            optimizer.step()

            # update pbar tqdm
            pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()
            processed += len(data)
            #train_loss += loss.item()
            pbar.set_description(desc= f'epoch = {i+1} Lr = {optimizer.param_groups[0]["lr"]}  Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')
        Lr_acc.append(100*correct/processed)
        Lr.append(optimizer.param_groups[0]['lr'])